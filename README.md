# FunFlow

> 一个高自由度的深度学习训练框架，提供从数据准备到模型部署的一站式解决方案

## ✨ 核心特性

- **高度灵活**：可适配任何深度学习任务
- **统一标准**：统一的数据准备格式和处理流程
- **模块化设计**：高度可定制的数据管道和模型架构
- **完整工作流**：数据处理 → 模型训练 → 推理评估 → 模型压缩 → 多格式导出
- **专注核心**：避免了大部分重复代码，你只需专注在你当前任务的特定处理即可
- **快速验证**：某些地方虽然不是最佳实践，但是非常适合快速验证想法

---

## 📋 目录

- [数据准备](#数据准备)
- [数据管道](#数据管道)
- [模型构建](#模型构建)
- [训练系统](#训练系统)
- [推理系统](#推理系统)
- [模型导出](#模型导出)
- [模型压缩](#模型压缩)
- [注册机制](#注册机制)
- [日志系统](#日志系统)
- [使用指南](#使用指南)
- [项目统计](#项目统计)

---

## 📊 数据准备

### 元数据格式（JSONL）

每一行都是一条 jsonline，示例：

```json
{"record_id": "eval_003091", "patient_id": "ID02_pd_2_0_0_readtext", "audio_path": "/data/data/parkinson_dataset/speech_dataset/silero_sliced/Parkinson/ID02_pd_2_0_0_readtext/ID02_pd_2_0_0_readtext_part10.wav", "modality": "audio", "audio_type": null, "sampling_rate": 16000, "duration": 5.896, "transcription": null, "label": "Parkinson", "vad_segments": null, "channels": 1}
{"record_id": "eval_001754", "patient_id": "adrso274", "audio_path": "/data/data/parkinson_dataset/speech_dataset/silero_sliced/Healthy/adrso274/adrso274_part16.wav", "modality": "audio", "audio_type": null, "sampling_rate": 16000, "duration": 5.128, "transcription": null, "label": "Healthy", "vad_segments": null, "channels": 1}
```

---

## 🔄 数据管道

### 在线数据管道

针对不同数据、任务，按照规范写 processor 即可。

### Processor 规范

Processor 由串联的一系列生成器构成：

#### 1. parse_raw（必须实现）
用于从 jsonl 中提取你需要的信息

#### 2-n. 一系列你需要的生成器（可选实现）
例如：
- 数据读取
- 数据预处理
- 滑窗处理
- 特征提取
- 数据增强
- 等等

#### n+1. shuffle（内部已实现）
样本级打乱

#### n+2. batch（内部已实现）
将样本按照指定 batch_size 分批

#### n+3. collate_fn（必须实现）
用于把数据整理成送入模型的形状并转为 tensor，然后以字典形式返回。

一般包含 `feats`、`labels` 等键，可根据任务返回所需的任何键，比如构造对比学习样本对之类的都可以。

---

## 🧠 模型构建

采用**模板方法模式**。

### 基类模型默认架构

```
preprocessing (upsampling, cmvn等) → backbone → neck → head → loss
```

通过配置文件来构造模型，没有配置的模块会被定义为 `Identity`（所以最终模型可能会包含几个 identity 模块，对性能的影响可以忽略，后续导出的时候，比如 torchscript 和 onnx 都会自动去掉多余的 identity 模块）。

当然你也可以选择不继承基类实现模型，或者直接把整个模型定义为 backbone 忽略其他所有模块即可。

### 核心方法

#### `_parse_inputs` ⭐

这是一个抽象方法，子类模型需要重写。

**这个方法有两个职责：**
1. 接受模型输入并进行类型和形状检查
2. 对接并解析数据管道的输出，从中取出需要进入模型的数据

#### `forward`

这是模型的前向传播，如果使用默认模型架构可无需重写。

**注意：** 输出必须是字典，你可以输出任何你需要的中间特征以及推理结果。

#### `forward_train`

针对模型训练时候的前向，相比 `forward` 方法多了损失计算这一个环节。

**输出规范：**
- 输出结果同样为字典，比 `forward` 方法的输出多了 `loss` 这个键
- `loss` 键对应的值可以是：
  - 一个字典包含多项损失（其中**必须包含 `loss` 字段用于表示总损失**，其余字段随意，所有字段都会出现在训练监控中）
  - 一个标量 tensor 表示总损失

设计损失函数的时候必需遵循这个规范。

---

## 🚀 训练系统

### train 和整个 trainer

train 和 trainer 都已经构造好了，无需任何改动。

**train** 负责编排，dataloader 构造，model 构造然后调用 trainer 进行训练。

### Trainer 核心组件

#### Optimizer
通过配置构造优化器

#### Scheduler
通过配置构造学习率调度策略

#### Hooks 钩子系统

**这个设计是训练自由度的关键**，核心思想是实现针对当前任务的代码和核心训练不变代码解耦。

具体实现是：你可以在训练开始前/结束后，每个 epoch 开始前/结束后，每个 batch/step 开始前/结束后，插入任意数量钩子实现任何你想做的事，这完全不会影响主 trainer 脚本。

##### 默认钩子

| 钩子 | 功能 |
|------|------|
| **LoggerHook** | 用于将训练日志写入文件，便于后续检查 |
| **EvalHook** | 用于验证集的指标评估。你需要实现针对当前任务的 evaluator 实例来对验证集计算任何你感兴趣的指标，更好的监控训练。evaluator 的实现需要继承基类，稍后会介绍 |
| **CheckpointHook** | 用于训练过程中的模型保存，可以设定保存数量上限，通过指定你最关注的指标来进行对比从而不断保存当前最优的指定数量模型 |

##### 可选钩子

| 钩子 | 功能 |
|------|------|
| **EarlystoppingHook** | 用于避免训练过程中的过拟合，通过设定容忍度，指定你最关注的指标来进行对比，如果模型在容忍度内仍然没有改进，则训练会提前停止 |
| **LRSchedulerHook** | 用于训练预热，可以为不包含预热的学习率策略提供预热能力 |
| **TensorBoardHook** | 用于可视化监控所有训练指标，验证指标，学习率调度 |
| **QATHook** | 用于在训练过程中控制量化观察器和 Norm 统计的冻结时机 |

### Evaluator 评估器

采用**模板方法模式**。

从 EvalHook 解耦出来根据当前任务实现，配合 EvalHook 计算你需要的指标。

#### 通常需要重写的方法

- **`_process_batch_labels`** - 用于从每个 batch 中提取出你的标签信息。batch 是一个字典，标签对应的键就是你的数据管道输出规定的键，可以有多个
- **`compute_metrics`** ⭐ - 抽象方法，必须实现。用于计算所有你需要的指标

---

## 🔍 推理系统

采用**模板方法模式**，实现推理逻辑。

### 核心组件

- **标准化定义推理结果数据类**
- **推理统计信息数据类**（计时）

### 推理器基类 base

后续推理需要根据当前任务继承基类实现推理器子类。

### 核心方法

| 方法 | 是否必须 | 功能说明 |
|------|----------|----------|
| **`load_model`** ⭐ | 必须实现 | 抽象方法，主要是考虑到需要加载不同格式的模型。utils 中的 model_loader 有提供 `load_pytorch_model` 方法用于加载 pytorch 格式模型，提供 `load_onnx_model` 方法用于加载 onnx 格式模型，提供 `load_qat_model` 用于加载 QAT 模型 |
| **`preprocess`** ⭐ | 必须实现 | 抽象方法，处理单个样本（如果是批量的话暂时也是循环调用 preprocess，待优化），输出特征用于模型推理。推荐参考配置文件中的验证数据处理方法 |
| **`forward`** ⭐ | 必须实现 | 抽象方法，模型前向推理，主要需要区分不同模型格式的推理方式 |
| **`postprocess`** ⭐ | 必须实现 | 抽象方法，逐个后处理每个样本（待优化） |
| **`compute_metrics`** | 可选 | 用于计算推理指标 |

### 工具支持

- **inference_cli** - 命令行工具

---

## 📦 模型导出

采用**模板方法模式**，实现导出逻辑。

### 实现导出器基类 base_exporter

#### 核心方法

| 方法 | 是否必须 | 功能说明 |
|------|----------|----------|
| **`load_model`** | 通常不需要重写 | 通过配置文件和 checkpoint 加载模型用于导出 |
| **`export`** ⭐ | 必须重写 | 抽象方法，实现具体的导出逻辑 |
| **`verify`** | 可选实现 | 验证导出前后模型输出是否一致 |

### 继承 base 实现通用 onnxexporter

#### 核心实现

- 由于模型设计规范是 dict 输出，而 onnx 不支持 dict 输出，需要对模型进行包装，转成单输出或者 tuple 输出
- 可对模型进行 simplify，优化模型架构，去除模型冗余结构（identity 等等）

### 工具支持

- **export_cli** - 命令行工具

---

## ⚙️ 模型压缩

目前支持 QAT 以及针对 onnx 的 PTQ（动态量化，静态量化）。

### PTQ - 训练后量化

#### 动态量化
- 通用方案
- 会生成量化报告

#### 静态量化
- 通用方案
- 会生成量化报告

### QAT - 量化训练

需配合模型设计、训练、层融合。

#### 实施步骤

##### 1. 模型设计
- 需插入量化桩
- 替换不支持量化的算子（concat、残差连接等）
- 如果存在无法量化也无法替换的算子，需插桩进行 DQD

##### 2. 训练
- 需配置量化后端
- 加载预训练权重
- 启用 QATHook
- 设置层融合策略等

##### 3. 层融合
- 需继承 `FusionStrategy` 基类实现针对当前模型的融合策略
- 实现层融合，通常是（Linear、Conv、ReLU、Norm）

---

## 🔧 注册机制

### 统一注册表

可避免繁复的导入问题，统一管理所有模块。

实现了通用注册表类 `Registry`：

- **装饰器方式注册**：`register`，可通过 `force` 参数避免重复注册问题
- **函数式注册**：`register_module`，可通过 `force` 参数避免重复注册问题

### 内置注册表

| 注册表 | 说明 |
|--------|------|
| `MODELS` | 自定义的模型都必须注册 |
| `PREPROCESSINGS` | 自定义的 preprocessing 模块都必须注册 |
| `BACKBONES` | 自定义的 backbone 都必须注册 |
| `NECKS` | 自定义的 neck 模块都必须注册 |
| `LOSSES` | 自定义的损失函数都必须注册 |
| `OPTIMIZERS` | 自定义的优化器都必须注册 |
| `SCHEDULERS` | 自定义的调度策略都必须注册 |
| `HOOKS` | 自定义的钩子都必须注册 |
| `EVALUATORS` | 自定义的评估器都必须注册 |
| `INFERENCERS` | 自定义的推理器都必须注册 |
| `EXPORTERS` | 自定义的导出器都必须注册 |
| `MODEL_LOADERS` | 自定义的模型加载器都必须注册 |
| `FUSION_STRATEGIES` | 自定义的层融合策略都必须注册 |

### 注册方式示例

```python
@MODELS.register('MyModel')
class MyModel(nn.Module):
    pass
```

### 自动注册

以在 FunFlow 项目下的 `__init__` 内部实现自动注册逻辑：
- FunFlow 下的所有模块都会被自动注册
- `local/` 下的自定义模块也会被扫描检测并自动注册

---

## 📝 日志系统

### 统一日志系统

整个系统可以使用同一个日志系统，统一管理日志。

### 日志级别

| 方法 | 输出位置 | 用途 |
|------|----------|------|
| `logger.debug` | 仅文件 | 调试信息，只写入文件 |
| `logger.info` | 仅文件 | 普通信息，只写入文件 |
| `logger.console` | 文件 + 终端 | 重要信息，写入文件并显示在终端 |
| `logger.warning` | 文件 + 终端 | 警告信息，写入文件并显示在终端 |
| `logger.error` | 文件 + 终端 | 错误信息，写入文件并显示在终端 |

---

## 🎯 使用指南

### 通常你需要实现的脚本

```
local/
├── data_2_jsonl.py              # 用于数据集划分 metadata 的生成
├── dataset/
│   └── processor.py             # 用于定义数据管道
├── model/
│   ├── model.py                 # 模型定义注册
│   └── loss.py                  # 损失定义注册等
├── evaluator/
│   └── evaluator.py             # 用于自定义评估模型
├── inference/
│   ├── inferencer.py            # 用于模型推理
│   └── onnxinferencer.py        # 用于 ONNX 模型推理
└── export/                      # 已经实现通用的 onnx 导出器
                                 # 如果有其他格式需要导出则需继承实现
```

### 标准工作流

通过 Shell 脚本来实现所有流程编排，常规流程：

| Stage | 步骤 | 说明 |
|-------|------|------|
| **Stage 0** | 数据准备 | 生成 JSONL 元数据 |
| **Stage 1** | 开始训练 | 模型训练 |
| **Stage 2** | 平均模型 | 模型集成 |
| **Stage 3** | 推理测试 | PyTorch 模型推理 |
| **Stage 4** | 导出 | 导出为 ONNX 等格式 |
| **Stage 5** | 导出测试 | ONNX 模型推理验证 |
| **Stage 6** | 静态量化 | PTQ 量化 |
| **Stage 7** | 量化测试 | 量化模型推理验证 |

---

## 📊 项目统计

### 代码量

**总代码量：12,486 行**

| 目录 | 行数 |
|------|------|
| 根目录文件 | 545 行 |
| bin | 594 行 |
| compression | 2,010 行 |
| datasets | 317 行 |
| export | 821 行 |
| inference | 703 行 |
| models | 3,857 行 |
| trainer | 1,981 行 |
| utils | 1,658 行 |

---

## 🚧 下一步计划

- [ ] **DDP 支持** - 分布式数据并行训练（暂时没有多卡可以测试，所以暂时未实现）
- [ ] **可解释性分析支持**
- [ ] **剪枝流程支持**
- [ ] **蒸馏流程支持**
- [ ] **修复 QAT 逻辑**
